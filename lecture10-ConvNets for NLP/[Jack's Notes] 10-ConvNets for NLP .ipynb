{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91544cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Zhengxiang (Jack) Wang \n",
    "# Date: 2021-10-11\n",
    "# GitHub: https://github.com/jaaack-wang \n",
    "# About: ConvNets for NLP for Stanford CS224N- NLP with Deep Learning | Winter 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd06afa",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- [1. Convolutional Nerual Netwrok (CNN)](#1)\n",
    "    - [1.1 Overview](#1-1)\n",
    "    - [1.2 2D example](#1-2)\n",
    "    - [1.3 1D example](#1-3)\n",
    "        - [1.3.1 With padding](#1-3-1)\n",
    "        - [1.3.2 With multiple filters](#1-3-2)\n",
    "        - [1.3.3 With Stride = 2](#1-3-3)\n",
    "        - [1.3.4 k-max pooling](#1-3-4)\n",
    "        - [1.3.5 Dilated CNN](#1-3-5)\n",
    "        - [1.3.6 PyTorch implementation (example)](#1-3-6)\n",
    "- [2. Yoon Kim (2014)](#2)\n",
    "    - [2.1 Single layer CNN for sentence classification](#2-1)\n",
    "    - [2.2 Hyperparameters](#2-2)\n",
    "    - [2.3 Model Variants and results](#2-3)\n",
    "- [3. Model comparisons, related techniques and applications](#3)\n",
    "    - [3.1 Comparisons: Bag of Vectors, Window Model, CNNs, RNNs](#3-1)\n",
    "    - [3.2 Techniques](#3-2)\n",
    "        - [3.2.1 Batch Normalization](#3-2-1)\n",
    "        - [3.2.2 1 x 1 Convolutions](#3-2-2)\n",
    "    - [3.3 Application](#3-3)\n",
    "        - [3.3.1 Translation](#3-3-1)\n",
    "        - [3.3.2 POS tagging](#3-3-2)\n",
    "        - [3.3.3 Character-Aware Neural Language Models](#3-3-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d48d26a",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "# 1. Convolutional Nerual Netwrok (CNN)\n",
    "\n",
    "<a name='1-1'></a>\n",
    "## 1.1 Overview\n",
    "\n",
    "- A good introduction to CNN can be found in [Andrew Ng's deep learning specilization](https://www.coursera.org/specializations/deep-learning?) on Coursera, specifically Course 4. \n",
    "- CNN is originally designed to deal with images, so it is usually used to extract features of two dimensions or three dimensions (depending on whether the image is colored or not). \n",
    "\n",
    "<a name='1-2'></a>\n",
    "## 1.2 2D example\n",
    "\n",
    "- 3D is similar, but with more layers for the filter\n",
    "- filter converts a patch into a single value\n",
    "\n",
    "<img src='../images/10-CNN2D.png' width='600' height='300'>\n",
    "\n",
    "\n",
    "<a name='1-3'></a>\n",
    "## 1.3 1D example\n",
    "\n",
    "<a name='1-3-1'></a>\n",
    "### 1.3.1 With padding\n",
    "- ∅ is optional padding (here = 1)\n",
    "- \\[∅, t, d\\] corresponds to the patch containing ∅ plus the first two words that the filter covers. so on and so forth.\n",
    "- Obviously, the filter here will only move up and down, no leftward or rightward.\n",
    "\n",
    "<img src='../images/10-CNN1D.png' width='600' height='300'>\n",
    "\n",
    "\n",
    "<a name='1-3-2'></a>\n",
    "### 1.3.2 With multiple filters\n",
    "\n",
    "- Different filters are said to be able to capture different dimensions of semantics/meanings, which of course are not always obvious by looking at the (visualized) results directly.\n",
    "- max pooling for convoluted values: 0.3, 1.6, 1.4 (for every column, namely, every filter)\n",
    "- average pooling: −0.87, 0.26, 0.53\n",
    "\n",
    "<img src='../images/10-CNN1D2.png' width='600' height='300'>\n",
    "\n",
    "<a name='1-3-3'></a>\n",
    "### 1.3.3 With Stride = 2\n",
    "- This is less useful in 1D setting\n",
    "- Stride is the gap between the position the filter covers in the last step and the position the filter covers in the this step \n",
    "<img src='../images/10-CNN1D3.png' width='600' height='300'>\n",
    "\n",
    "- local max pooling \n",
    "<img src='../images/10-CNN1D4.png' width='600' height='300'>\n",
    "\n",
    "<a name='1-3-4'></a>\n",
    "### 1.3.4 k-max pooling\n",
    "\n",
    "- I did not see this mentioned in Andrew Ng's course. Also seems to be not very often used. \n",
    "<img src='../images/10-CNN1D5.png' width='600' height='300'>\n",
    "\n",
    "<a name='1-3-5'></a>\n",
    "### 1.3.5 Dilated CNN\n",
    "\n",
    "- Never see this before!\n",
    "- This is basically CNN within another CNN. 1, 3, 5 refers to the 1st, 3rd and 5th rows of the first convulated table and so on.\n",
    "\n",
    "<img src='../images/10-CNN1D6.png' width='600' height='300'>\n",
    "\n",
    "\n",
    "<a name='1-3-6'></a>\n",
    "### 1.3.6 PyTorch implementation (example)\n",
    "\n",
    "<img src='../images/10-pyTorchImplemntation.png' width='600' height='300'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeab369",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "# 2. Yoon Kim (2014)\n",
    "\n",
    "- Reference:  Yoon Kim (2014): Convolutional Neural Networks for Sentence Classification. EMNLP 2014. https://arxiv.org/pdf/1408.5882.pdf\n",
    "- This is a short and simple paper, but worth studying. \n",
    "\n",
    "<a name='2-1'></a>\n",
    "## 2.1 Single layer CNN for sentence classification\n",
    "\n",
    "- CNN used: A variant of convolutional NNs of [Collobert, Weston et al. (2011)](https://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf)\n",
    "\n",
    "<img src='../images/10-modelArc.png' width='600' height='300'>\n",
    "\n",
    "\n",
    "- Goal: Sentence classification:\n",
    "    - Mainly positive or negative sentiment of a sentence\n",
    "- Other tasks like:\n",
    "    - Subjective or objective language sentence\n",
    "    - Question classification:about person, location, number,...\n",
    "\n",
    "- A similar paper: Zhang and Wallace (2015) A Sensitivity\n",
    "Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification\n",
    "https://arxiv.org/pdf/1510.03820.pdf\n",
    "\n",
    "<img src='../images/10-modelArc2.png' width='600' height='300'>\n",
    "\n",
    "\n",
    "<a name='2-2'></a>\n",
    "## 2.2 Hyperparameters\n",
    "\n",
    "\n",
    "<img src='../images/10-hyperparameters.png' width='600' height='300'>\n",
    "\n",
    "\n",
    "\n",
    "<a name='2-3'></a>\n",
    "## 2.3 Model Variants and results\n",
    "\n",
    "<img src='../images/10-modelVariants.png' width='600' height='300'>\n",
    "\n",
    "<img src='../images/10-results.png' width='600' height='300'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ac8e14",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "# 3. Model comparisons, related techniques and applications\n",
    "\n",
    "\n",
    "<a name='3-1'></a>\n",
    "## 3.1 Comparisons: Bag of Vectors, Window Model, CNNs, RNNs\n",
    "\n",
    "<img src='../images/10-models.png' width='600' height='300'>\n",
    "\n",
    "<a name='3-2'></a>\n",
    "## 3.2 Techniques\n",
    "\n",
    "\n",
    "<a name='3-2-1'></a>\n",
    "### 3.2.1 Batch Normalization\n",
    "\n",
    "- Reference: [Ioffe and Szegedy. 2015. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv:1502.03167.](https://arxiv.org/pdf/1502.03167.pdf)\n",
    "- Often used in CNNs\n",
    "- Transform the convolution output of a batch by scaling the activations to have zero mean and unit variance (similar to Z-transform of statistics)\n",
    "- Use of BatchNorm makes models much less sensitive to parameter initialization, since outputs are automatically rescaled\n",
    "- PyTorch: nn.BatchNorm1d\n",
    "\n",
    "\n",
    "<a name='3-2-2'></a>\n",
    "### 3.2.2 1 x 1 Convolutions\n",
    "\n",
    "- [Lin, Chen, and Yan. 2013. Network in network. arXiv:1312.4400.](https://arxiv.org/pdf/1312.4400.pdf)\n",
    "- 1 x 1 convolutions, a.k.a. Network-in-network (NiN)\n",
    "connections, are convolutional kernels with kernel_size=1\n",
    "- A 1 x 1 convolution gives you a fully connected linear layer across channels!\n",
    "- It can be used to map from many channels to fewer channels\n",
    "- 1 x 1 convolutions add additional neural network layers with very few additional parameters\n",
    "    - Unlike Fully Connected (FC) layers which add a lot of parameters\n",
    "\n",
    "\n",
    "<a name='3-3'></a>\n",
    "## 3.3 Application\n",
    "\n",
    "<a name='3-3-1'></a>\n",
    "### 3.3.1 Translation\n",
    "\n",
    "- Reference: [Kalchbrenner and Blunsom (2013) “Recurrent Continuous Translation Models”](https://aclanthology.org/D13-1176.pdf)\n",
    "\n",
    "<img src='../images/10-cnnApp.png' width='600' height='300'>\n",
    "\n",
    "\n",
    "<a name='3-3-2'></a>\n",
    "### 3.3.2 POS tagging\n",
    "\n",
    "- Reference: [Dos Santos and Zadrozny (2014). Learning Character-level Representations for Part-of-Speech Tagging](http://proceedings.mlr.press/v32/santos14.pdf)\n",
    "\n",
    "<img src='../images/10-cnnApp2.png' width='600' height='300'>\n",
    "\n",
    "\n",
    "<a name='3-3-3'></a>\n",
    "### 3.3.3 Character-Aware Neural Language Models\n",
    "\n",
    "- Reference: [Kim, Jernite, Sontag, and Rush 2015. Character-Aware Neural Language Models](https://arxiv.org/pdf/1508.06615.pdf)\n",
    "- Abstract: We describe a simple neural language model that relies only on character-level inputs. Predictions are still made at the word-level. Our model employs a convolutional neural network (CNN) and a highway network over characters, whose output is given to a long short-term memory (LSTM) recurrent neural network language model (RNN-LM). On the English Penn Treebank the model is on par with the existing state-of-the-art despite having 60% fewer parameters. On languages with rich morphology (Arabic, Czech, French, German, Spanish, Russian), the model outperforms word-level/morpheme-level LSTM baselines, again with fewer parameters. The results suggest that on many languages, character inputs are sufficient for language modeling. Analysis of word representations obtained from the character composition part of the model reveals that the model is able to encode, from characters only, both semantic and orthographic information.\n",
    "\n",
    "\n",
    "<font color=\"blue\"> There are also other models introduced in the lecture, but in a way that is too board as well as too complicated to capture precisely. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981cff5c",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "# 4. References\n",
    "\n",
    "- [Course website](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/index.html)\n",
    "\n",
    "- [Lecture video](https://youtu.be/EAJoRA0KX7I) \n",
    "\n",
    "- [Lecture slide](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/slides/cs224n-2019-lecture11-convnets.pdf)\n",
    "\n",
    "- [Yoon Kim (2014): Convolutional Neural Networks for Sentence Classification. EMNLP 2014.](https://arxiv.org/pdf/1408.5882.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
